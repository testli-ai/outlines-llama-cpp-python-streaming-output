[project]
name = "outlines-llama-cpp-python-streaming-output"
version = "0.1.0"
description = "A demonstration project showcasing the integration of outlines and llama-cpp-python for structured JSON generation with streaming output. It leverages llama.cpp for local model inference and outlines for schema-based text generation."
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "huggingface-hub>=0.29.1",
    "outlines[llamacpp]>=0.2.1",
    "pydantic>=2.10.6",
]

[dependency-groups]
dev = [
    "ruff>=0.9.9",
]
